name: bibtex_inference_net_wNCE_simplified
program: wandb_allennlp
method: random
command:
  - ${program}
  - "--subcommand=train"
  - "--include-package=structured_prediction_baselines"
  - "--config_file=model_configs/multilabel_classification/bibtex_inference_net_wDVN_fscratch.jsonnet"
  - "--wandb_project structured_prediction_baselines"
  - "--wandb_entity score-based-learning"
  - "--wandb_tags=task=mlc,scoreNN=NCE,taskNN=inference_net,dataset=bibtex"
  - ${args} 
parameters:
metric:
  name: best_validation_fixed_f1
  goal: maximize
parameters:
  # Environment variables.
  env.cross_entropy_loss_weight:
    max: 2
    min: 0
    distribution: uniform
  env.ff_dropout:
    values: [0.5]
  env.ff_hidden:
    values: [400]
  env.ff_linear_layers:
    values: [2]
  env.global_score_hidden_dim:
    values: [200]
  env.inference_score_weight:
    values: [1]
  env.num_samples:
    values: [30]
  # Direct config variables.
  model.sampler.optimizer.lr:
    distribution: log_uniform
    max: 0
    min: -10
  model.sampler.stopping_criteria:
    values: [10]
  trainer.optimizer.lr:
    distribution: log_uniform
    max: 0
    min: -7
  trainer.optimizer.weight_decay:
    distribution: log_uniform
    max: -2
    min: -12