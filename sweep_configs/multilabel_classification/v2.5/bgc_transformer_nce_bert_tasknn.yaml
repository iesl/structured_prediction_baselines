name: bgc_transformer_nce_bert_tasknn
description: "Scorenn consisting of transformer trained using nce objective with tasknn consisting of BERT. Here tasknn is non-pretrained transformer."
program: allennlp
command:
- ${program}
- train_with_wandb
- model_configs/multilabel_classification/v2.5/bgc_transformer_nce_bert_tasknn.jsonnet
- --include-package=structured_prediction_baselines
- --wandb_tags="task=text_mlc,model=tasknn,sampler=inference_net,dataset=bgc,inference_module=inference_net,inference_module=tasknn,sampler=tasknn,scorenn=bert_nce"
- ${args}
- --file-friendly-logging

method: grid
metric:
  goal: maximize
  name: "validation/best_fixed_f1"

early_terminate:
  type: hyperband
  min_iter: 4

parameters:
  env.score_nn_weight_decay:
    values: [0.001, 0.1]
  env.score_nn_embedding:
    value: 300
  env.score_nn_dropout_10x:
    value: 0.1
  env.score_nn_transformer_layers:
    value: 4
  env.score_nn_transformer_attn_heads:
    value: 3
  env.task_nn_dropout_10x:
    value: 0.3
  env.task_nn_weight_decay:
    values: [0.1, 0.001]
  trainer.optimizer.optimizers.task_nn.lr:
    value: 0.00005
  trainer.optimizer.optimizers.score_nn.lr:
    values: [0.001, 0.0001, 0.00005]
  trainer.num_steps.task_nn:
    value: 1
  trainer.num_steps.score_nn:
    value: 1
  env.score_loss_weight:
    values: [0.1, 1.0, 3.0] 
  env.cross_entropy_loss_weight:
     value: 1
  env.global_score_hidden_dim:
    value: 300
